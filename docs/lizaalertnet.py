# -*- coding: utf-8 -*-
"""Copy of Copy of LizaAlertNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_Yq7S1oFLl9Lxc_Q7p0RY7jD9JcMq4xN
"""

# Предсказание
import torch
from torch import nn
import torchvision
import torchvision.transforms as transforms
from torchvision import models

# Предобработка
from PIL import Image
from numpy import asarray
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

"""# 1. Поработаем с данными

- 1.1 Загрузить датасет с гугл диска
- 1.2 Конвертировать изображения в формат для pyTorch
- 1.3.1 Поделить выборку на validation и train
- 1.3.2 Создать подходящий для обучения data_loader 

"""

COLAB = True

if COLAB:
  from google.colab import drive
  drive.mount('/content/gdrive')

# this creates a symbolic link so that now the path /content/gdrive/My\ Drive/ is equal to /mydrive
!ln -s /content/gdrive/My\ Drive/lizaalert /mydrive
!ls /mydrive

print("Loading CSV...")
liza_alert_data = pd.read_csv("/mydrive/razm.csv" if COLAB else "TODO:SPECIFY", encoding="UTF-8")
liza_alert_data.head()

# Обнаружилось, что в датасете есть непригодные к обучению картинки (непонятного формата)
liza_alert_data[~liza_alert_data["Названия"].str.contains('.jpg',case=False)].head()
print("Процент плохих картинок: " + str(liza_alert_data[~liza_alert_data["Названия"].str.contains('.jpg',case=False)].shape[0]/liza_alert_data.shape[0] * 100) + '%')

# Уберем непригодные к обучению картинки, поскольку они составляют незначительную часть датасета
liza_alert_data = liza_alert_data[liza_alert_data["Названия"].str.contains('.jpg',case=False)]

# Уберем лишние картинки
import os
liza_alert_data = liza_alert_data[[os.path.isfile('/mydrive/data_without_videos/' + i) for i in liza_alert_data['Названия']]]

liza_alert_data.head()

# Проверим на NaN
liza_alert_data.isnull().any()

"""Сейчас датасет почти в готовом состоянии - но осталось:

- Заменить названия картинок на сами картинки
- Применить one-hot encoding для времени суток \ года как для категориальных признаков.

# One-hot encoding? - Неее
Было выявлено три категориальных признака:
- Время суток
- Время года
- Местность

Мы раздробили задачу на множество подзадач многоклассовой классификации - поэтому категориальные признаки, собранные в одном месте это лучшая подмога нам, поскольку мыслительный процесс нейросети касательно дня \ ночи будет проходить в одном месте, и следственно обучаться проще.
"""

# # Заменим время суток на названия
# def numToDayTime(num):
#   if num == 0:
#     return 'NoDayTime'
#   if num == 1:
#     return 'День'
#   if num == 2:
#     return 'Ночь'
#   if num == 3:
#     return 'Рассвет/закат'
# transform = transforms.ToTensor()
# liza_alert_data['Время суток'] = liza_alert_data['Время суток'].map(numToDayTime)
# liza_alert_data.head()

# # Заменим время года на названия
# def numToYearTime(num):
#   if num == 0:
#     return 'NoYearTime'
#   if num == 1:
#     return 'Зима'
#   if num == 2:
#     return 'Весна'
#   if num == 3:
#     return 'Лето'
#   if num == 4:
#     return 'Осень'
# transform = transforms.ToTensor()
# liza_alert_data['Время года'] = liza_alert_data['Время года'].map(numToYearTime)
# liza_alert_data.head()

# # Заменим местность на названия
# def numToPlace(num):
#   if num == 0:
#     return 'NoPlace'
#   if num == 1:
#     return 'Лес'
#   if num == 2:
#     return 'Город'
# transform = transforms.ToTensor()
# liza_alert_data['Местность'] = liza_alert_data['Местность'].map(numToPlace)
# liza_alert_data.head()

# # One-hot encoding 
# dummy1 = pd.get_dummies(liza_alert_data['Время суток'], drop_first=True)
# dummy1.head()

# # One-hot encoding
# dummy2 = pd.get_dummies(liza_alert_data['Время года'], drop_first=True)
# dummy2.head()

# # One-hot encoding
# dummy3 = pd.get_dummies(liza_alert_data['Местность'], drop_first=True)
# dummy3.head()

# liza_alert_data = pd.concat([liza_alert_data, dummy1], axis=1).drop('Время суток', axis=1)
# liza_alert_data = pd.concat([liza_alert_data, dummy2], axis=1).drop('Время года', axis=1)
# liza_alert_data = pd.concat([liza_alert_data, dummy3], axis=1).drop('Местность', axis=1)

# liza_alert_data.head()

train_data = liza_alert_data

train_data.head()

"""# Пишем кастомный датасет"""

# Напишем кастомный датасет для pyTorch

from torch.utils.data import Dataset, DataLoader
import cv2
import os
class LizaAlertDataset(Dataset):
    def __init__(self, pandasFrame, transform, basedir, part):
        # initialize the arrays to store the ground truth labels and paths to the images
        self.image_paths = []
        # self.avia = []
        # self.color_labels = []
        # self.gender_labels = []
        # self.article_labels = []

        self.image_paths = pandasFrame['Названия'].values
        self.images = []

        self.label_avia = pandasFrame['Авиа'].values
        self.label_auto = pandasFrame['Автомобили'].values
        self.label_bpla = pandasFrame['БПЛА'].values
        self.label_diver = pandasFrame['Водолаз'].values
        self.label_cynologist = pandasFrame['Кинолог'].values
        self.label_horses = pandasFrame['Кони'].values
        self.label_hugs = pandasFrame['Объятия'].values
        self.label_sherp = pandasFrame['Шерп'].values
        self.label_timeday = pandasFrame['Время суток'].values
        self.label_timeyear = pandasFrame['Время года'].values        
        self.label_place = pandasFrame['Местность'].values

        self.transform = transform
        self.basedir = basedir



        # Load self.images
        self.part = part
        n_images = 0
        for img_path in self.image_paths:
           img = Image.open(self.basedir + '/' + img_path)
           if self.transform:
             img = self.transform(img)
           self.images.append(img)
           n_images += 1
           if (n_images % 50 == 0):
              print(f"{n_images} from {len(self.image_paths)/(1/part)}")
           if (n_images > len(self.image_paths)/(1/part)):
             print(str(n_images) + " has been loaded")
             break
       

        self.classes = [
          'label_avia',
          'label_auto',
          'label_bpla',
          'label_diver',
          'label_cynologist',
          'label_horses',
          'label_hugs',
          'label_sherp',
          'label_timeday',
          'label_timeyear',
          'label_place',
        ]



    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        dict_data = {
            'image': self.images[idx],
            'labels':{
                'label_avia': self.label_avia[idx],
                'label_auto': self.label_auto[idx],
                'label_bpla': self.label_bpla[idx],
                'label_diver': self.label_diver[idx],
                'label_cynologist': self.label_cynologist[idx],
                'label_horses': self.label_horses[idx],
                'label_hugs': self.label_hugs[idx],
                'label_sherp': self.label_sherp[idx],
                'label_timeday': self.label_timeday[idx],
                'label_timeyear': self.label_timeyear[idx],
                'label_place': self.label_place[idx],
            },
        }
      
        
        return dict_data

transform = transforms.Compose( 
            [
              transforms.Resize((256,256)),
              # transforms.RandomCrop(224),
              transforms.ToTensor()
            ]
        )
# Самый времязатратный процесс
lad = LizaAlertDataset(train_data, transform=transform, basedir='/mydrive/data_without_videos', part=0.65)
print(len(lad))

import matplotlib.pyplot as plt
from pprint import pprint
idx = 0
plt.imshow(np.asarray(np.asarray(lad[idx]['image'].squeeze().permute(1,2,0))))
plt.show()
pprint([f'{k}: {v}' for k,v in lad[idx]['labels'].items()])

"""# Поделим данные на тест и валидацию, и загрузим в DataLoader'ы"""

batch_size = 128
max_epoch_number = 120
learning_rate = 1e-3
from torch.utils.data import DataLoader
training_data, test_data = torch.utils.data.random_split(lad, [int(2*len(lad)/4), int(2*len(lad)/4)], generator=torch.Generator().manual_seed(42))
train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)
print(len(train_loader))
print(len(test_loader))

sample = next(iter(train_loader))

print("Keys in our sample batch: {}".format(sample.keys()))
print("Size for the images in our sample batch: {}".format(sample['image'].shape))
print("Size for the target in our sample batch: {}".format(sample['labels']['label_timeday'].shape))
print("Targets for each batch in our sample: {}".format(sample['labels']['label_timeyear']))

"""# Наша модель - основанная на resnet34"""

class MultilabelClassifier(torch.nn.Module):
    def __init__(self, 
          n_avia=2, 
          n_auto=2,                
          n_bpla=2,
          n_diver=2,
          n_cynologist=2,
          n_horses=2,
          n_hugs=2,
          n_sherp=2,
          n_timeOfTheDay=4,
          n_timeOfTheYear=5,
          n_place=3,       
        ):
        super().__init__()
        self.resnet = torchvision.models.resnet34(pretrained=True)
        self.model_wo_fc = torch.nn.Sequential(*(list(self.resnet.children())[:-1]))



        self.avia = torch.nn.Sequential(
            torch.nn.Dropout(p=0.2),
            torch.nn.Linear(in_features=512, out_features=n_avia),
            # torch.nn.Softmax()
        )
        self.auto = torch.nn.Sequential(
            torch.nn.Dropout(p=0.2),
            torch.nn.Linear(in_features=512, out_features=n_auto),
            # torch.nn.Softmax()
        )

        self.bpla = torch.nn.Sequential(
            torch.nn.Dropout(p=0.2),
            torch.nn.Linear(in_features=512, out_features=n_bpla),
            # torch.nn.Softmax()
        )
        self.diver = torch.nn.Sequential(
            torch.nn.Dropout(p=0.2),
            torch.nn.Linear(in_features=512, out_features=n_diver),
            # torch.nn.Softmax()
        )
        self.cynologist = torch.nn.Sequential(
            torch.nn.Dropout(p=0.2),
            torch.nn.Linear(in_features=512, out_features=n_cynologist),
            # torch.nn.Softmax()
        )
        self.horses = torch.nn.Sequential(
            torch.nn.Dropout(p=0.2),
            torch.nn.Linear(in_features=512, out_features=n_horses),
            # torch.nn.Softmax()
        )
        self.hugs = torch.nn.Sequential(
            torch.nn.Dropout(p=0.2),
            torch.nn.Linear(in_features=512, out_features=n_hugs),
            # torch.nn.Softmax()
        )
        self.sherp = torch.nn.Sequential(
            torch.nn.Dropout(p=0.2),
            torch.nn.Linear(in_features=512, out_features=n_sherp),
            # torch.nn.Softmax()
        )
        self.timeOfTheDay = torch.nn.Sequential(
            torch.nn.Dropout(p=0.2),
            torch.nn.Linear(in_features=512, out_features=n_timeOfTheDay),
            # torch.nn.Softmax()
        )
        self.timeOfTheYear = torch.nn.Sequential(
            torch.nn.Dropout(p=0.2),
            torch.nn.Linear(in_features=512, out_features=n_timeOfTheYear),
            # torch.nn.Softmax()
        )
        self.place = torch.nn.Sequential(
            torch.nn.Dropout(p=0.2),
            torch.nn.Linear(in_features=512, out_features=n_place),
            # torch.nn.Softmax()
        )


    def forward(self, x):
        x = self.model_wo_fc(x)
        x = torch.flatten(x, 1)

        return {
          'avia': self.avia(x),           
          'auto': self.auto(x),                
          'bpla': self.bpla(x),
          'diver': self.diver(x),
          'cynologist': self.cynologist(x),
          'horses': self.horses(x),
          'hugs': self.hugs(x),
          'sherp': self.sherp(x),
          'timeday': self.timeOfTheDay(x),
          'timeyear': self.timeOfTheYear(x),
          'place': self.place(x),       
        }

"""Проверим работоспособность (на всякий случай)"""

model = MultilabelClassifier()

sample = next(iter(train_loader)) 

import matplotlib.pyplot as plt
from pprint import pprint
idx = 0
plt.imshow(np.asarray(np.asarray(sample['image'][0].squeeze().permute(1,2,0))))
plt.show()
pprint([f'{k}: {v.cpu().numpy()[0]}' for k,v in sample['labels'].items()])

pred = model((sample['image'][:1]))

def predToRes(pred):
  res = {}
  for k,v in pred.items():
    res[k] = v.argmax().item()
  return res

pprint(predToRes(pred))

"""# Можно приступать к обучению!"""

# Переведём в cuda...
if torch.cuda.is_available():
    model.cuda()
model.train()

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

"""### Цикл обучения"""

# from sklearn.metrics import *
# def calculate_metrics(pred, target, threshold=0.5):
#     pred = np.array(pred > threshold, dtype=float)
#     return {
#             # 'micro/precision': precision_score(y_true=target, y_pred=pred, average='micro'),
#             # 'micro/recall': recall_score(y_true=target, y_pred=pred, average='micro'),
#             # 'micro/f1': f1_score(y_true=target, y_pred=pred, average='micro'),
#             'macro/precision': precision_score(y_true=target, y_pred=pred, average='macro'),
#             'macro/recall': recall_score(y_true=target, y_pred=pred, average='macro'),
#             'macro/f1': f1_score(y_true=target, y_pred=pred, average='macro'),
#             # 'samples/precision': precision_score(y_true=target, y_pred=pred, average='samples'),
#             # 'samples/recall': recall_score(y_true=target, y_pred=pred, average='samples'),
#             # 'samples/f1': f1_score(y_true=target, y_pred=pred, average='samples'),
#             }
    # from sklearn.metrics import f1_score

def criterion(loss_func,outputs,pictures):
  losses = 0
  for i, key in enumerate(outputs):
    losses += loss_func(outputs[key], pictures['labels'][f'label_{key}'].to(device))
  return losses

def training(model,device,lr_rate,epochs,train_loader):
  num_epochs = epochs
  losses = []
  checkpoint_losses = []
  stat = []
  optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)
  n_total_steps = len(train_loader)

  loss_func = nn.CrossEntropyLoss()

  for epoch in range(num_epochs):
     for i, pictures in enumerate(train_loader):
        images = pictures['image'].to(device)
        pictures = pictures

        outputs = model(images)

        loss = criterion(loss_func,outputs, pictures)
        losses.append(loss.item())

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i+1) % (int(n_total_steps/1)) == 0:
            checkpoint_loss = torch.tensor(losses).mean().item()
            checkpoint_losses.append(checkpoint_loss)
            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {checkpoint_loss:.4f}')
            
            # # Calc Metric
            # model.eval()
            # with torch.no_grad():
            #     # F1 append
            #     corpse = next(iter(test_loader))
            #     _f1_score = f1_score(np.array(list(corpse['labels'].values())), np.array(list(predToRes(model(corpse['image'])).values())))
            #     stat.append(_f1_score)
            # model.train()



  return checkpoint_losses

checkpoint_losses_2 = training(model, device, 0.0001, 100, train_loader)

import seaborn as sns
sns.set_theme()
import matplotlib.pyplot as plt
print(checkpoint_losses)
plt.plot(checkpoint_losses)
plt.ylabel('Loss')
plt.xlabel('Iteration')
plt.show()

import matplotlib.pyplot as plt
print(checkpoint_losses_2, )
plt.plot(range(100,200), checkpoint_losses_2,)
plt.ylabel('Loss')
plt.xlabel('Iteration')
plt.show()

import matplotlib.pyplot as plt
print(checkpoint_losses_2, )
plt.plot(range(0,200), checkpoint_losses + checkpoint_losses_2,)
plt.ylabel('Loss')
plt.xlabel('Iteration')
plt.show()

# import matplotlib.pyplot as plt
# print(stat)
# plt.plot(stat)
# plt.ylabel('F1')
# plt.show()

torch.save(model, '/mydrive/backup/model_last_gpu__lastlast.pth')

assert False

"""# 3. Протестировать модель ручками!

"""

def upload():
  from google.colab import files
  uploaded = files.upload() 
  for name, data in uploaded.items():
    with open(name, 'wb') as f:
      f.write(data)
      print ('saved file', name)
      return name
filename = upload()

# model = torch.load('/mydrive/backup/model_last.pth')
# torch.save(model, '/mydrive/backup/model_last_gpu.pth')

device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')
device
# model.load_state_dict(torch.load('/mydrive/backup/model_iter_2133_epoch_82.pth', map_location=device))
model.eval()

photo = transform(Image.open(filename))
plt.imshow(photo.permute(1,2,0))
plt.show()
if torch.cuda.is_available():
  photo = photo.to(device)
photo = photo.unsqueeze(0)

pred = model(photo)

pprint(predToRes(pred))

"""# (⊙_⊙) оно работает

# Метрики модели
48 часов без сна приводят к тому что методы из библиотеки применять не получается. Быстрее было написать свой F1. Так мы и сделали.
"""

model.eval()
def evalu(model,device,test_loader, field):
  tp,fp,fn,tn=0,0,0,0
  outputs = 0
  for i, pictures in enumerate(test_loader):
        with torch.no_grad():
        
            images = pictures['image'].to(device)
            pictures = pictures

            outputs = model(images)
            outpootis = np.array([k.argmax().item() for k in outputs[field]])

            truth = pictures['labels'][f'label_{field}'].numpy()
            prediction = outpootis
            for i in range(0, len(prediction)):
              if truth[i] == prediction[i] and truth[i] == 1:
                tp+=1
              if truth[i] != prediction[i] and truth[i] == 1:
                fn+=1
              if truth[i] == prediction[i] and truth[i] == 0:
                tn+=1
              if truth[i] != prediction[i] and truth[i] == 0:
                fp+=1
            
            # for k in zip(list(outputs.values())):
            # break


  precision = tp / (tp+fp)
  recall = tp / (tp+fn)
  f1 = 2*tp / (2*tp + fp + fn)
  return f1

device=torch.device('cpu')
model = torch.load('/mydrive/backup/model_last_gpu__lastlast.pth')
model = model.to(device)
test_loader = DataLoader(test_data, batch_size=1, shuffle=True)

#Last weights
device=torch.device('cpu')
model = torch.load('/mydrive/backup/model_last_gpu__lastlast.pth')
model = model.to(device)
test_loader = DataLoader(test_data, batch_size=1, shuffle=True)
print(lad.classes)
f1_last = [
  evalu(model, device, test_loader, 'avia'),
  evalu(model, device, test_loader, 'auto'),
  evalu(model, device, test_loader, 'bpla'),
  evalu(model, device, test_loader, 'diver'),
  evalu(model, device, test_loader, 'cynologist'),
  evalu(model, device, test_loader, 'horses'),
  evalu(model, device, test_loader, 'hugs'),
  evalu(model, device, test_loader, 'sherp'),
]
print(f1_last)

#F1 for 200 iterations
print('%.10f' % (sum(f1_last)/8))

"""### Ура! Модель не переобучилась, чего мы очень боялись, и вышла довольно точной. Ура! Всё было не зря!

## Предсказание для приватного датасета
"""

